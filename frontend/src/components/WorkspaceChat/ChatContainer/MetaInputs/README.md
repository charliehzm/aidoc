# Meta Response

**Meta Response** enhances the chat experience by introducing contextually aware input fields, thereby making interactions both intuitive and dynamic. This feature uses an autogenerated JSON meta object to guide the front-end on rendering various input interfaces—ranging from options and suggestions to sliders—thus extending beyond traditional text inputs.

## How It Works

1. Click on Workspace setting Cog symbol.
2. Navigate to Chat Settings
3. Enable Meta Response (to the bottom)
4. Navigate to the newly added Meta Response Tap (top right).
5. Type an active sequence prompt following the examples below, or try `proactive prompting Demo` from System Prompts Tab.
6. Go to the chat area and ask a question such `I want to know about tallest 5 buildings in the world`, or just start you sequence.

> [!IMPORTANT] Using more advanced LLM such as GPT-4 will return consistent results

To see Meta Response in action, watch our quick demo:
<a href="https://vimeo.com/928815869"><img width="960" alt="Screenshot 2024-03-30 at 06 14 25" src="https://github.com/Mintplex-Labs/anything-llm/assets/90522472/736f1073-a39a-4785-b51b-464c60212ae1"></a>

![CPT2403300731-896x596](https://github.com/Mintplex-Labs/anything-llm/assets/90522472/746955c6-2b6d-4c5a-8549-4659021ce7b7)

Meta Response enables dynamic input methods to enhance user experience by allowing for intuitive and context-sensitive interactions. It instructs the model to incorporates a JSON meta object within responses to guide the front-end on how to render various input interfaces, such as options, suggestions, or sliders, moving beyond traditional text inputs.

### Key Features

- **Meta Object Schema**: Structures input types (options, range, multi-select checkboxes) and the necessary data for rendering.
- **JSON Object Extractor**: Converts meta JSON objects from responses into objects passed to chatHistory.
- **Input Handler Module (DynamicInput)**: Dynamically changes user input methods based on instructions from the meta object.
- **Rendering Components**: Includes components like OptionsSelect, offering dropdown menus, lists, buttons, etc., with more to be added.
- **Configurable Settings**: Users can enable the Meta Response feature from chat settings, detailed in the provided Figma design link.

[View Figma Design](https://www.figma.com/proto/35TjnuK1Hy0QemBvhHu5Mg/anythingllm?type=design&node-id=218-930&t=27fVVWvxAUG4WK4E-0&scaling=min-zoom&page-id=203%3A863&starting-point-node-id=218%3A930)

This system is built with modularity and scalability in mind, incorporating a library of standalone input method components and a flexible schema for future enhancements.

### Usage Example

By typing a sequence system prompt where you will ask the model to add options, and if you want to specify the options input `displayType` you can chose from `dropdown`, `list`, `buttons`, `checkbox` for multiple choices.
in case of integers, you can as it to use a `range` between 2 number, or In case of Star rating, you can instruct the model to return `rating` and it will understand how to implement that.

```bash
Interaction Sequence
1. ask the user to select the number of options that should be presented
return: range between 2 to 10
1. if list is not provided, ask the user to provide a list, be helpful by providing some suggestions to start with, ask user to chose one, or just click "use Keyboard input" to type any other list.
   return: options of 4 best lists in full markdown, associated with json options  of displayType buttons in json object
2. complement the user about his choice and proceed by presenting the list items, ask user to chose one, or just click "use Keyboard input" to type any other item if they has one in mind.
   return: options of 4 items in full markdown, associated with json options  of displayType buttons in json object
3. Provide information about the item, break down the information to options.
   return: information about the item in full markdown add simplified comparison table with closest item add as well fun fact, associated with break down of the information to list of options, displayType checkbox with sub-label "I can break down this information further".
4. Provide  information about what they asked.
   Return: information in full markdown, references, and simplified example if possible, a mermaid chart for illustration. associated with two options ether to dig deeper where you will go back to step 5, or start over where you will go back to step 1,   displayType dropdown with sub-label "would you like top know more...",
5. check if user want to ether 1. Dig deeper  or 2. switch to a new topic.
   return: Two options 1. ask the user if they want to switch topic, if yes then move to Next step #8 for rating, option 2 dig deeper about the underlying [topic], if user select it then go to step 3.  use displayType dropdown with sub-label "would you like top know more...",
6. ask the user to rate the latest question
return: rating using rating json, if rating is 2 or less, go to next step to ask for fee back, if more than 2 then go to step 1
1. feed back
return: don't return options json object, as the user will typed his comment. then go to step 1.
```

#### Example JSON Meta Object:

```json
{
  "inputs": {
    "type": "options",
    "data": {
      "options": [
        {
          "label": "Restart Router",
          "value": "restart router"
        },
        {
          "label": "Check Service Status",
          "value": "check service status"
        }
      ],
      "label": "Select Server ",
      "description": "list of servers as described"
    },
    "settings": {
      "allowMultiple": false,
      "displayType": "chose one, buttons/list/dropdown"
    }
  },
  "sentiment": "happy",
  "style": "text"
}
```

### Screen shots:

#### components:

Range Slicder Input:

<table>
<tr>
<td>
<img alt="AnythingLLM-Your-personal-LLM-trained-on-anything" src="https://github.com/Mintplex-Labs/anything-llm/assets/90522472/d8b89a17-75bf-4325-acb4-1c9826c8afc7"/>
</td><td>
<img alt="AnythingLLM-Your-personal-LLM-trained-on-anything" src="https://github.com/Mintplex-Labs/anything-llm/assets/90522472/8a55394f-5311-48f4-8909-902f27c9ae94" />
</td>
</tr>
</table>

Buttons Input:

<table>
<tr>
<td>
<img alt="AnythingLLM-Your-personal-LLM-trained-on-anything" src="https://github.com/Mintplex-Labs/anything-llm/assets/90522472/add85d3e-80d7-419b-9eb9-4b3a0b30cc43"/>
</td><td>
<img alt="AnythingLLM-Your-personal-LLM-trained-on-anything" src="https://github.com/Mintplex-Labs/anything-llm/assets/90522472/20ac1811-f6cd-4dd5-9882-7d7d00443d9e" />
</td>
</tr>
</table>
Dropdown menu Input:
<table>
<tr>
<td>
<img alt="AnythingLLM-Your-personal-LLM-trained-on-anything" src="https://github.com/Mintplex-Labs/anything-llm/assets/90522472/48c764e8-046b-425e-bcab-f43f2ae4554b"/>
</td><td>
<img alt="AnythingLLM-Your-personal-LLM-trained-on-anything" src="https://github.com/Mintplex-Labs/anything-llm/assets/90522472/6720062d-311a-4bfb-bf46-e8a9be8903e8" />
</td>
</tr>
</table>
Star Rating Input:
<table>
<tr>
<td>
<img alt="AnythingLLM-Your-personal-LLM-trained-on-anything" src="https://github.com/Mintplex-Labs/anything-llm/assets/90522472/bf9b12f6-a94d-4a85-8c55-6d6eadcd931e"/>
</td><td>
<img alt="AnythingLLM-Your-personal-LLM-trained-on-anything" src="https://github.com/Mintplex-Labs/anything-llm/assets/90522472/1b6a25f9-5d3f-4437-a25a-7a9aa942bc38" />
</td>
</tr>
</table>

#### Meta response settings area:

Enable Meta Response toggle switch.
![AnythingLLM-Your-personal-LLM-trained-on-anything (32)](https://github.com/Mintplex-Labs/anything-llm/assets/90522472/4cf73c50-8034-4f7f-90ce-ae4ac0b11c1f)

By enabling Meta Response, users will get access to the Meta Response Menu, where they can edit both the system prompt and Schema prompts, adding and removing components and more. Enabling Meta Response will automatically disable editing system prompt form this screen. View image below.
![AnythingLLM-Your-personal-LLM-trained-on-anything (33)](https://github.com/Mintplex-Labs/anything-llm/assets/90522472/134c2605-f029-4236-a7cf-5b038bfd725f)

Meta Response menu, this is a seed for many other Meta elements, we are starting with Inputs where you will can input data via alternative input methods than text. late there are plans to add Custom outputs, to dynamically control the conversation output.. etc
![AnythingLLM-Your-personal-LLM-trained-on-anything (29)](https://github.com/Mintplex-Labs/anything-llm/assets/90522472/2dc780a3-fe09-4754-a632-c80bb4f8d1de)

### Enabling Inputs:

**Overview:**

With the Inputs feature now activated, users gain access to a control panel designed to customize and enhance their interaction experience. Below is a detailed guide to the functionality available within this panel:

**Legend:**

1.  **Input Feature Toggle**: A switch that allows users to effortlessly activate or deactivate the Inputs feature. This provides flexibility in how interactions are managed and displayed.
2.  **System Prompt Toggle**: This switch controls the visibility of the System Prompt. It's especially useful when the system prompt is not required, allowing for a cleaner interface.
3.  **System Prompt Management Buttons**: These buttons are your toolkit for customizing the System Prompt. Users can add, remove, or rename various system prompts to fit their needs, ensuring that the chat interface is always relevant and tailored.
4.  **System Prompt Text Area**: This field displays the current system prompt and allows for real-time editing. Expanding this area reveals the full text, and changes are saved promptly, demonstrated by the opening of a save dialog. An example of an active system prompt is provided for reference.
5.  **Input Schema Text Area**: For those looking to dive deeper into customization, this area allows for the modification of the Input Schema. Here, users can adjust the behavior of input fields for more advanced control, enhancing the interaction according to specific requirements.
6.  **Component Activation Area**: This section is designed for enabling or disabling various components within the Inputs feature. It offers a granular level of control over which elements are active at any given time, allowing users to fine-tune their interaction setup.

![AnythingLLM-Your-personal-LLM-trained-on-anything (19)](https://github.com/Mintplex-Labs/anything-llm/assets/90522472/16cd1b09-69ce-4d84-ab93-114ee29a068a)

By integrating Meta Response, users gain access to a versatile and intuitive chat experience, opening new dimensions of interaction beyond mere text.
